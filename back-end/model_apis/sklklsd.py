#!/usr/bin/env python3
"""
Simple Flask wrapper to serve the trained model "sklklsd"
Auto-generated by tools/generate_model_api.py
"""
from flask import Flask, request, jsonify
import pickle
import json
import os
import traceback

# Optional preprocessing import (uses project's model_serializer if available)
try:
    from model_serializer import PreprocessingPipeline
except Exception:
    PreprocessingPipeline = None

app = Flask(__name__)

# Load model
MODEL_PATH = r"/home/mohamed/Desktop/BEN/machine-learning-model-builder/back-end/models/model_18_sklklsd.pkl"
metadata = dict()

try:
    with open(MODEL_PATH, 'rb') as f:
        model = pickle.load(f)
except Exception as e:
    print('Failed to load model pickle:', e)
    model = None

# Initialize preprocessing pipeline if metadata and class available
preprocessor = None
if PreprocessingPipeline is not None and metadata:
    try:
        preprocessor = PreprocessingPipeline(
            label_encoders=metadata.get('label_encoders'),
            scaler=metadata.get('scaler')
        )
    except Exception as e:
        print('Failed to init PreprocessingPipeline:', e)


@app.route('/health', methods=['GET'])
def health():
    return jsonify({'success': True, 'loaded': model is not None})


def predict_input_dict(input_dict: dict):
    """Convert a single input dict to model-ready format and predict."""
    try:
        if preprocessor is not None and metadata:
            # Preprocess using project's pipeline if available
            input_features = metadata.get('input_features') or list(input_dict.keys())
            X = preprocessor.preprocess_input(input_dict, input_features)
        else:
            # Fallback: assume values in input_dict are ordered feature vector
            if isinstance(input_dict, dict):
                X = [list(input_dict.values())]
            else:
                X = [input_dict]

        preds = model.predict(X)
        # If predict returns numpy types, convert to python
        try:
            result = preds[0].tolist() if hasattr(preds[0], 'tolist') else preds[0]
        except Exception:
            result = preds[0]
        return {'success': True, 'prediction': result}
    except Exception as e:
        traceback.print_exc()
        return {'success': False, 'error': str(e)}


@app.route('/predict', methods=['POST'])
def predict():
    payload = request.get_json(force=True)
    if not payload:
        return jsonify({'success': False, 'error': 'Missing JSON body'}), 400

    # Accept either {"input": {...}} or raw list/array
    input_data = payload.get('input') if isinstance(payload, dict) else payload
    if input_data is None:
        return jsonify({'success': False, 'error': 'Missing "input" in JSON body'}), 400

    res = predict_input_dict(input_data)
    status = 200 if res.get('success') else 500
    return jsonify(res), status


@app.route('/predict_batch', methods=['POST'])
def predict_batch():
    payload = request.get_json(force=True)
    if not payload:
        return jsonify({'success': False, 'error': 'Missing JSON body'}), 400

    inputs = payload.get('inputs') if isinstance(payload, dict) else payload
    if not inputs or not isinstance(inputs, list):
        return jsonify({'success': False, 'error': 'Missing "inputs" (list) in JSON body'}), 400

    results = []
    for inp in inputs:
        r = predict_input_dict(inp)
        results.append(r)

    return jsonify({'success': True, 'results': results})


if __name__ == '__main__':
    port = int(os.getenv('PORT', 8000))
    print(f'Starting Flask API on port {port}...')
    app.run(host='0.0.0.0', port=port, debug=False)
