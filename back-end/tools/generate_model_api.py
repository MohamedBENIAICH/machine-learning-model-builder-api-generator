#!/usr/bin/env python3
"""
Generate a standalone Flask app file that serves a trained model (pickle) as an API.

Usage:
  python generate_model_api.py --model-id 1 --outdir ../model_apis
  or
  python generate_model_api.py --model-name "Loan Approval Model" --pickle ./models/1_model.pkl --outdir ../model_apis

The script will create a file named after the model (sanitized) in the output directory.
The generated file exposes two endpoints:
  - POST /predict  -> single prediction (JSON {"input": {...} })
  - POST /predict_batch -> batch predictions (JSON {"inputs": [{...}, {...}]})

The generated app will try to use the project's PreprocessingPipeline and metadata if available.
"""
import argparse
import os
import json
import textwrap
import sys

# Try to import project database helper to fetch model info by id
try:
    sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
    from database import get_db
except Exception:
    get_db = None


def sanitize_name(name: str) -> str:
    return ''.join(c if (c.isalnum() or c in ('_', '-')) else '_' for c in name).lower()


def generate_file_content(model_name: str, pickle_path: str, metadata_path: str | None):
    safe_name = sanitize_name(model_name)
    
    # Build the content by concatenating strings instead of using a giant f-string
    metadata_load = ""
    if metadata_path:
        metadata_load = f"""
    # Attempt to load metadata
    try:
        with open(r'{metadata_path}', 'r', encoding='utf-8') as f:
            metadata = json.load(f)
    except Exception as e:
        print('Warning: failed to load metadata:', e)
        metadata = dict()
"""

    # Build template as raw string, then substitute only the needed parts
    content = '''#!/usr/bin/env python3
"""
Simple Flask wrapper to serve the trained model "%s"
Auto-generated by tools/generate_model_api.py
"""
from flask import Flask, request, jsonify
import pickle
import json
import os
import traceback

# Optional preprocessing import (uses project's model_serializer if available)
try:
    from model_serializer import PreprocessingPipeline
except Exception:
    PreprocessingPipeline = None

app = Flask(__name__)

# Load model
MODEL_PATH = r"%s"
metadata = dict()%s

try:
    with open(MODEL_PATH, 'rb') as f:
        model = pickle.load(f)
except Exception as e:
    print('Failed to load model pickle:', e)
    model = None

# Initialize preprocessing pipeline if metadata and class available
preprocessor = None
if PreprocessingPipeline is not None and metadata:
    try:
        preprocessor = PreprocessingPipeline(
            label_encoders=metadata.get('label_encoders'),
            scaler=metadata.get('scaler')
        )
    except Exception as e:
        print('Failed to init PreprocessingPipeline:', e)


@app.route('/health', methods=['GET'])
def health():
    return jsonify({'success': True, 'loaded': model is not None})


def predict_input_dict(input_dict: dict):
    """Convert a single input dict to model-ready format and predict."""
    try:
        if preprocessor is not None and metadata:
            # Preprocess using project's pipeline if available
            input_features = metadata.get('input_features') or list(input_dict.keys())
            X = preprocessor.preprocess_input(input_dict, input_features)
        else:
            # Fallback: assume values in input_dict are ordered feature vector
            if isinstance(input_dict, dict):
                X = [list(input_dict.values())]
            else:
                X = [input_dict]

        preds = model.predict(X)
        # If predict returns numpy types, convert to python
        try:
            result = preds[0].tolist() if hasattr(preds[0], 'tolist') else preds[0]
        except Exception:
            result = preds[0]
        return {'success': True, 'prediction': result}
    except Exception as e:
        traceback.print_exc()
        return {'success': False, 'error': str(e)}


@app.route('/predict', methods=['POST'])
def predict():
    payload = request.get_json(force=True)
    if not payload:
        return jsonify({'success': False, 'error': 'Missing JSON body'}), 400

    # Accept either {"input": {...}} or raw list/array
    input_data = payload.get('input') if isinstance(payload, dict) else payload
    if input_data is None:
        return jsonify({'success': False, 'error': 'Missing "input" in JSON body'}), 400

    res = predict_input_dict(input_data)
    status = 200 if res.get('success') else 500
    return jsonify(res), status


@app.route('/predict_batch', methods=['POST'])
def predict_batch():
    payload = request.get_json(force=True)
    if not payload:
        return jsonify({'success': False, 'error': 'Missing JSON body'}), 400

    inputs = payload.get('inputs') if isinstance(payload, dict) else payload
    if not inputs or not isinstance(inputs, list):
        return jsonify({'success': False, 'error': 'Missing "inputs" (list) in JSON body'}), 400

    results = []
    for inp in inputs:
        r = predict_input_dict(inp)
        results.append(r)

    return jsonify({'success': True, 'results': results})


if __name__ == '__main__':
    port = int(os.getenv('PORT', 8000))
    print(f'Starting Flask API on port {port}...')
    app.run(host='0.0.0.0', port=port, debug=False)
'''
    return content % (model_name, pickle_path, metadata_load)


def main():
    parser = argparse.ArgumentParser(description='Generate Flask API file for a trained model')
    parser.add_argument('--model-id', type=int, help='Model ID from database')
    parser.add_argument('--model-name', type=str, help='Model name (if not using model-id)')
    parser.add_argument('--pickle', type=str, help='Path to model pickle file (overrides DB value)')
    parser.add_argument('--metadata', type=str, help='Path to metadata JSON (optional)')
    parser.add_argument('--outdir', type=str, default=os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'model_apis')),
                        help='Output directory for generated API file')

    args = parser.parse_args()

    model_info = None
    if args.model_id and get_db is not None:
        try:
            db = get_db()
            model_info = db.get_model(args.model_id)
        except Exception as e:
            print('Warning: failed to fetch model from DB:', e)

    if not model_info and args.model_name:
        # Try to find model by name via get_all_models if available
        if get_db is not None:
            try:
                db = get_db()
                all_models = db.get_all_models(limit=1000, offset=0)
                for m in all_models:
                    if m.get('model_name', '').lower() == args.model_name.lower():
                        model_info = db.get_model(m['id'])
                        break
            except Exception as e:
                print('Warning: failed to search models in DB:', e)

    if not model_info and not args.pickle:
        print('Error: could not determine model info from DB, and no --pickle provided')
        parser.print_help()
        sys.exit(1)

    # Determine model name and pickle path
    model_name = args.model_name or (model_info.get('model_name') if model_info else 'model')
    pickle_path = args.pickle or (model_info.get('model_file_path') if model_info else None)
    metadata_path = args.metadata or None

    if not pickle_path:
        print('Error: pickle path is required (either --pickle or model record must include model_file_path)')
        sys.exit(1)

    os.makedirs(args.outdir, exist_ok=True)
    safe_name = sanitize_name(model_name)
    out_file = os.path.join(args.outdir, f"{safe_name}.py")

    content = generate_file_content(model_name=model_name, pickle_path=os.path.abspath(pickle_path), metadata_path=metadata_path)

    with open(out_file, 'w', encoding='utf-8') as f:
        f.write(content)

    print('Generated API file:', out_file)
    print('Run it with: python', out_file)


if __name__ == '__main__':
    main()
